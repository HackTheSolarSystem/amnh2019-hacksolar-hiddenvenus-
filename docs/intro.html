<html>
    <head>
        <script>
        MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
        }
        };
        </script>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <meta charset="UTF-8"/>
    <link href="/docs/style.css" rel="stylesheet" type="text/css"/>
    </head>
    <body><nav id="site-nav"><a href="/docs/index.html">Index</a><span class="nav-spacer">|</span><a href="/docs/intro.html">Introduction to Project</a><span class="nav-spacer">|</span><a href="/docs/details/satellite.html">How Magellan Orbited Venus</a></nav><p><a href="https://drive.google.com/open?id=1JvPmGv5QkmYR3dWunUkGzPd2EFIvhrY0">This presentation</a> has an introduction to our work and a little bit about how far we&rsquo;ve come.</p><p>The following will build on what&rsquo;s in the above presentation.</p><h1 id="what-are-we-doing">What are we doing?</h1><p>We&rsquo;re trying to create an elevation map for the planet of Venus. An elevation map is just like a regular map, except for every latitude and longitude, we will know the height of the land. Mountains will be high, valleys will be low, plains will generally be in the middle.</p><p>We&rsquo;d like to create a picture of the Venusian surface that can be referenced by latitude and longitude; stored at the latitude and longtitude will be a number which states how high the surface is at that location.</p><h1 id="why-hasnt-this-been-done-already--background">Why Hasn&rsquo;t this been done already / Background</h1><p>Before we continue, let&rsquo;s look at some background of this mission. People produce elevations maps all the time of Earth. Of buildings, cities, and the whole globe. It&rsquo;s common. The challenges of this project lie in what makes this job different from others; what makes existing tools incompatible with the information available.</p><p>People have been looking at Venus since they&rsquo;ve had telescopes. There were prior attempts to image Venus&rsquo; surface. Chapter 1 of the Magellan Guide speaks more about this; early attempts gave scientists just enough detail of the terrain for them to know they needed even more detail. Enough detail to raise questions about Venus&rsquo; terrain. So the Magellan mission was organized. The missions right before Magellan were the Soviet Veneras 15 and 16 which obtained radar images of 25% of Venus&rsquo; surface with resolution $1km$ or better.</p><p>The Magellan satellite was launched on May 4, 1989 and arrived at Venus August 10, 1990. Mapping operations started September 15, 1990 and ended around September 1992 (mgn-guide page 4).</p><p>What did the magellan mission achieve?</p><ul><li>Image data of 98% of venus&rsquo; surface, many areas imaged more than  once with different imaging geometries and/or directions of  illumination.</li><li>Altimeter data&mdash;basically the thing we&rsquo;re trying to get with this  project. Rather than take pictures, radiation was used to measure the distance of the satellite from the ground.</li><li>Some other measurements.</li></ul><p>Magellan carried an altimeter on board, but the resolution of the height data is very large&mdash;on the order of 10km in between each sample, and is not always reliable. In mountainous regions, errors in altitude can be as large as a kilometer (radar-venus&ndash;1991 page 1). The point of this project is to get elevation measurements of better resolution.</p><p>There is another possiblity, though. We have elevation maps and 3D models of the Earth, cities, and buildings. We tend to use photogrammetry for that; we figure out how tall things are by taking pictures from different perspectives under similar lighting conditions. This is called <em>stereogrammetry</em>. Applying stereogrammetry to optical photos is called <em>photogrammetry,</em> and applying stereogrammetry to radar images is called <em>radargrammetry</em>. This works somewhat like how we percieve depth; by seeing something from two different perspectives (our two eyeballs), differences in the locations of the object clue us into how large and far away the object is.</p><p>Many space missions have used stereogrammetry to study the altimetry of different planets. The mission happened before later tools for stereogrammetry (getting elevation data from a pair of images from different perspectives of the same region) were developed. So the data isn&rsquo;t immediately usable with known tools for performing stereogrammetry. Common stereogrammetry tools aren&rsquo;t compatible with it for futher reasons: this is radar data, not optical data and must be handled a little differently; and most tools can&rsquo;t handle planetary data.</p><h2 id="key-sources">Key Sources</h2><ul><li>Data from the Magellan mission is available  <a href="http://pds-geosciences.wustl.edu/mgn/mgn-v-rdrs-5-bidr-full-res-v1/">here</a></li><li>The Magellan Software Interface Specification (SIS) for the F-BIDR  files located in <code>papers+documents/MGN-FBIDR-SIS-SDPS-101-RevE.pdf</code>.  Each F-BIDR is a collection of 20 files (and some extra metadata  files, whose extension is <code>.lbl</code>) which contain both image data and  metadata about the image and spacecraft. This document describes the  binary format of some of the files in detail (Files 12&ndash;19), and also  describes the meaning of the information, but is not sufficient  alone for interpretation. From here on in, will be called just <em>FBIDR SIS</em>.</li><li>The Guide to Magellan Image Interpretation located in  <code>papers+documents/19940013181.pdf</code>. This is broader in scope and  less terse than the F-BIDR SIS. It goes over details of the mission,  contains a lot of definitions for important terms and concepts in  the way that satellites function, and the way that the radar on the  satellite functions as well. For actual image interpretation,  Chapters 2 and 5 of this document are valuable.  From here on, will be called just <em>Magellan Guide</em>.  The guide is also <a href="https://history.nasa.gov/JPL-93-24/jpl_93-24.htm">available  here</a></li></ul><h2 id="problems-what-are-we-trying-to-overcome">Problems: what are we trying to overcome?</h2><p>Lastly, the actual images are not optical images; they are not created by reflected visible light from a surface. This was done for different reasons, but one of them being thick clouds that cover Venus. Radiation that could penetrate the clouds had to be used.</p><p>So for an accurate map of elevation for Venus, techniques that rely on images of the surface have to be used, because that&rsquo;s what&rsquo;s available, could produce results more accurate and at higher resolutions than the on-board altimeter.</p><h2 id="what-do-the-pictures-mean-and-where-are-they-in-the-data">What do the pictures mean, and where are they in the data?</h2><p>There&rsquo;s supposed to be image data of Venus&rsquo; surface. Where?</p><p>Each F-BIDR is a collection of 20 files, much of which is metadata. Files 12&ndash;19, as specified in the FBIDR SIS are comprised of pieces called <em>logical records</em>. Files 13 and 15 have logical records which contain both satellite metadata and image data from the radar. The satellite metadata helps us understand which part of Venus&rsquo; surface the image corresponds to, so that the pieces can be joined together into larger pictures which represent a whole orbit, or multiple orbits.</p><p>Each pixel represents $75m^2$ of Venus&rsquo; surface. They&rsquo;re 75m wide and tall. A radar on Magellan emitted radiation from a small dish and captured some of the radiation back a small amount of time later. The intensity of the pixel is the intensity of the reflected radiation. What precisely this means we can&rsquo;t quite say yet. More reading to do. It&rsquo;s easier to start off with what it <em>isn&rsquo;t</em>.</p><ul><li>It&rsquo;s not brightness of the surface. The radiation isn&rsquo;t visible and  the radar wasn&rsquo;t affected by visible light (we assume).</li><li>It has nothing to do with color of the surface (we assume).</li></ul><p>What the intensities tell us is how capable a given patch of land was at reflecting the radiation back toward the satellite. Chapter 5 of the Magellan Guide goes into more detail about this, but here&rsquo;s a summary. First, an image describing various terms on satellite orientation toward the surface. The <em>SAR</em> is the radar dish on the magellan satellite. If I talk about satellite orientation, I&rsquo;m really talking about the orientation of this dish.</p><div class="figure"><img src="readme-images/satellite-info.png" alt="Demonstration of satellite orientation terms"/><p class="caption">Demonstration of satellite orientation terms</p></div><p>A note: incidence angle and look angle are <em>not</em> the same. On the radar swath in the image (the shaded grey bar on the surface) is a thin black line that crosses the swath, along with a squiggly. The line represents an assumed reference surface, and the squiggly is the actual surface. The reference surface is flat in the picture, but it doesn&rsquo;t have to be. Actual surfaces often aren&rsquo;t flat. The picture-in-picture insert describes this well: there&rsquo;s the <em>local</em> incidence angle, which is the actual incidence angle the radiation makes with the actual (squiggly) ground.</p><p>There&rsquo;s a few things that affect how capable a patch of land is at reflecting radiation: the <em>incidence angle</em> (the angle between the radiation and the surface struck by it), the roughness of the ground, and the patch having very reflective materials. If a patch has more reflective materials, then generally the intensity of the pixel representing that patch will be greater. For the other two parameters, the explanation is less straightforward; incidence angle and roughness have an interplay, as shown in the following 2 figures:</p><div class="figure"><img src="readme-images/incidence-angle-land-demo.png" alt="Demonstration of reflectivity of 2 different
surfaces"/><p class="caption">Demonstration of reflectivity of 2 different surfaces</p></div><p>In the very top image, the surface is flat so it acts like a mirror. Radiation hits it and then bounces away. If the incidence angle is small, then the radiation will probably bounce back toward the radar causing very bright intensity (radar-bright); if the incidence angle is large, then the flat ground will show up dark (radar-dark).</p><p>The more rough the ground, the less intensity will shoot right back at the radar in any one direction because the radiation will be spread out in different directions; however regardless of the incidence angle, radiation is more likely to go back to the radar than miss it. The following graph shows this in more detail. Higher radar backscatter means higher pixel intensity.</p><div class="figure"><img src="readme-images/incidence-angle-reflection-graph.png" alt="Backscatter vs incidence angle for different
surfaces"/><p class="caption">Backscatter vs incidence angle for different surfaces</p></div><p>Notice that the graph for rough ground changes less with incidence angle while the graph for flat ground changes a lot with incidence angle.</p><p>Here&rsquo;s two radar images of some mountains in California which display the difference between different incidence angles. They&rsquo;re of the same region; the dark bottom of the top image is not the night sky (we thought it was for a moment), but <em>flat ground</em> from a high incidence angle ($50^\circ$). There are bright dots in the dark region of the top photo; look for them in the bottom photo to be able to compare the two regions. The pictures are basically the same scale and width and height.</p><div class="figure"><img src="readme-images/incidence-angle-land-effects.png" alt="Comparison of incidence angle effects at California
Mountains"/><p class="caption">Comparison of incidence angle effects at California Mountains</p></div></body>
</html>